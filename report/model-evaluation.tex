\section{Model Evaluation}

Each model was trained on a portion of the data (training set) and evaluated on
a separate, unseen portion (test set). Metrics such as accuracy, precision,
recall, and F1-score were used to assess the performance of each model. These
metrics provide insights into how well the models classified the gamma and
hadron events.

\begin{description}
    \item[Accuracy] Measures the overall proportion of correctly classified
    events.
    \item[Precision] Measures the proportion of predicted gamma events that were
    actually gamma events.
    \item[Recall] Measures the proportion of actual gamma events that were
    correctly predicted as gamma.
    \item[F1-Score] A harmonic mean of precision and recall, providing a
    balanced view of model performance.
\end{description}

By comparing the performance metrics across all models, the most suitable model
for classifying gamma and hadron events could be identified.
